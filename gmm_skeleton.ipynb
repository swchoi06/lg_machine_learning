{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from copy import deepcopy\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import scipy.stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set three centers, the model should predict similar results\n",
    "center_1 = np.array([1,1])\n",
    "center_2 = np.array([5,5])\n",
    "center_3 = np.array([8,1])\n",
    "\n",
    "# Generate random data and center it to the three centers\n",
    "sigma = 1.5\n",
    "data_1 = sigma*np.random.randn(20,2) + center_1\n",
    "data_2 = sigma*np.random.randn(20,2) + center_2\n",
    "data_3 = sigma*np.random.randn(20,2) + center_3\n",
    "\n",
    "data = np.concatenate((data_1, data_2, data_3), axis = 0)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1], s=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance Caculator\n",
    "def dist(a, b, ax=1):\n",
    "    return np.linalg.norm(a - b, axis=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "k = 3\n",
    "# Number of training data\n",
    "n = data.shape[0]\n",
    "# Number of features in the data\n",
    "c = data.shape[1]\n",
    "\n",
    "# Generate random centers, here we use sigma and mean to ensure it represent the whole data\n",
    "mean = np.mean(data, axis = 0)\n",
    "std = np.std(data, axis = 0)\n",
    "\n",
    "# Initial parameters\n",
    "mean = np.random.randn(k,c)*std + mean\n",
    "covar = np.stack((np.identity(c),)*k)\n",
    "coeff = np.array([1/k]*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting along with the Centroids\n",
    "plt.scatter(data[:,0], data[:,1], c='#050505', s=7)\n",
    "plt.scatter(mean[:,0], mean[:,1], marker='*', s=200, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store old parameter\n",
    "mean_old = np.zeros(mean.shape)\n",
    "covar_old = np.zeros(covar.shape)\n",
    "coeff_old = np.zeros(coeff.shape)\n",
    "\n",
    "# responsibility\n",
    "resp = np.zeros((n, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define normal distrbution pdf\n",
    "pdf = lambda mean, stdev, x: scipy.stats.multivariate_normal(mean, stdev).pdf(x)\n",
    "\n",
    "def calc_error(mean, mean_old, covar, covar_old, coeff, coeff_old):\n",
    "    # Error func. - Distance between new parameters and old parameters\n",
    "    # TODO\n",
    "    return error\n",
    "\n",
    "error = -1\n",
    "# Loop will run till the error becomes zero\n",
    "while error <= 0:\n",
    "    # Calculate responsibility\n",
    "    # TODO\n",
    "    # Store old parameters\n",
    "    mean_old = deepcopy(mean)\n",
    "    covar_old = deepcopy(covar)\n",
    "    coeff_old = deepcopy(coeff)\n",
    "    \n",
    "    # Calculate mean, covar, coeff\n",
    "    mean = np.zeros(mean.shape)\n",
    "    covar = np.zeros(covar.shape)\n",
    "    coeff = np.zeros(coeff.shape)\n",
    "    # TODO\n",
    "    error = calc_error(mean, mean_old, covar, covar_old, coeff, coeff_old)\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.zeros((n, 3))\n",
    "for i in range(n):\n",
    "    color[i] = np.array([resp[i][0], resp[i][1], resp[i][2]])\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(data[:, 0], data[:, 1], s=7, c=color)\n",
    "ax.scatter(mean[:, 0], mean[:, 1], marker='*', s=200, c='#050505')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function\n",
    "# TODO\n",
    "print(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm(k, data):\n",
    "    # Number of training data\n",
    "    n = data.shape[0]\n",
    "    # Number of features in the data\n",
    "    c = data.shape[1]\n",
    "\n",
    "    # Generate random centers, here we use sigma and mean to ensure it represent the whole data\n",
    "    mean = np.mean(data, axis = 0)\n",
    "    std = np.std(data, axis = 0)\n",
    "\n",
    "    # Initial parameters\n",
    "    mean = np.random.randn(k,c)*std + mean\n",
    "    covar = np.stack((np.identity(c),)*k)\n",
    "    coeff = np.array([1/k]*k)\n",
    "    \n",
    "    # To store old parameter\n",
    "    mean_old = np.zeros(mean.shape)\n",
    "    covar_old = np.zeros(covar.shape)\n",
    "    coeff_old = np.zeros(coeff.shape)\n",
    "\n",
    "    # responsibility\n",
    "    resp = np.zeros((n, k))\n",
    "    \n",
    "    \n",
    "    error = -1\n",
    "    # Loop will run till the error becomes zero\n",
    "    while error <= 0:\n",
    "        # Calculate responsibility\n",
    "        # TODO\n",
    "        # Store old parameters\n",
    "        mean_old = deepcopy(mean)\n",
    "        covar_old = deepcopy(covar)\n",
    "        coeff_old = deepcopy(coeff)\n",
    "    \n",
    "        # Calculate mean, covar, coeff\n",
    "        mean = np.zeros(mean.shape)\n",
    "        covar = np.zeros(covar.shape)\n",
    "        coeff = np.zeros(coeff.shape)\n",
    "        # TODO\n",
    "        error = calc_error(mean, mean_old, covar, covar_old, coeff, coeff_old)\n",
    "        \n",
    "    # Objective function\n",
    "    likelihood = -1\n",
    "    # TODO\n",
    "        \n",
    "    return math.log(likelihood)\n",
    "\n",
    "likelihood = np.zeros(5)\n",
    "for i in range(5):\n",
    "    likelihood[i] = gmm(i+1, data)\n",
    "    print(\"Likelihood for K = \" + str(i+1) + \" : \" + str(likelihood[i]))\n",
    "\n",
    "plt.plot(np.arange(1, 6), likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
